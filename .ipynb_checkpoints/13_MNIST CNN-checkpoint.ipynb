{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<small>\n",
    "Copyright (c) 2017 Andrew Glassner\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "</small>\n",
    "\n",
    "\n",
    "\n",
    "# Deep Learning From Basics to Practice\n",
    "## by Andrew Glassner, https://dlbasics.com, http://glassner.com\n",
    "------\n",
    "## Chapter 21: Convolutional Neural Networks (CNNs)\n",
    "### Notebook 2: Run MNIST\n",
    "\n",
    "This notebook is provided as a “behind-the-scenes” look at code used to make some of the figures in this chapter. It is still in the hacked-together form used to develop the figures, and is only lightly commented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Much of this file comes from Keras demo code\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "# Just in case the Keras defaults aren't as we expect\n",
    "from keras import backend as K_backend\n",
    "K_backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a File_Helper for saving and loading files.\n",
    "\n",
    "save_files = True\n",
    "\n",
    "import os, sys, inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "sys.path.insert(0, os.path.dirname(current_dir)) # path to parent dir\n",
    "from DLBasics_Utilities import File_Helper\n",
    "file_helper = File_Helper(save_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 6s 1us/step\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 202s 3ms/step - loss: 0.2716 - acc: 0.9156 - val_loss: 0.0610 - val_acc: 0.9804\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 160s 3ms/step - loss: 0.0894 - acc: 0.9731 - val_loss: 0.0396 - val_acc: 0.9870\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 172s 3ms/step - loss: 0.0676 - acc: 0.9801 - val_loss: 0.0343 - val_acc: 0.9886\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 146s 2ms/step - loss: 0.0552 - acc: 0.9840 - val_loss: 0.0301 - val_acc: 0.9894\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 145s 2ms/step - loss: 0.0460 - acc: 0.9859 - val_loss: 0.0278 - val_acc: 0.9910\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 145s 2ms/step - loss: 0.0420 - acc: 0.9873 - val_loss: 0.0304 - val_acc: 0.9899\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 144s 2ms/step - loss: 0.0379 - acc: 0.9886 - val_loss: 0.0293 - val_acc: 0.9908\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 143s 2ms/step - loss: 0.0366 - acc: 0.9893 - val_loss: 0.0279 - val_acc: 0.9911\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 142s 2ms/step - loss: 0.0339 - acc: 0.9899 - val_loss: 0.0271 - val_acc: 0.9912\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 145s 2ms/step - loss: 0.0294 - acc: 0.9902 - val_loss: 0.0272 - val_acc: 0.9912\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 143s 2ms/step - loss: 0.0288 - acc: 0.9909 - val_loss: 0.0265 - val_acc: 0.9914\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 144s 2ms/step - loss: 0.0276 - acc: 0.9916 - val_loss: 0.0272 - val_acc: 0.9922\n",
      "Test loss: 0.027215828553938354\n",
      "Test accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs = list(range(1,1+len(history.history['acc'])))\n",
    "plt.plot(xs, history.history['acc'], label='training accuracy')\n",
    "plt.plot(xs, history.history['val_acc'], label='validation accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlim(1, len(xs))\n",
    "file_helper.save_figure('mnist-history')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_x = 8\n",
    "grid_y = 3\n",
    "plt.figure(figsize=(1*grid_x, 2*grid_y))\n",
    "for y in range(grid_y):\n",
    "    for x in range(grid_x):\n",
    "        index = x + (grid_x * y)\n",
    "        plt_index = x + (grid_x * y)\n",
    "        plt.subplot(2*grid_y, grid_x, 1+plt_index)\n",
    "        img_index = index+500\n",
    "        pred_data = np.reshape(x_test[img_index], (1, 28, 28, 1))\n",
    "        pred = model.predict(pred_data, verbose=0)\n",
    "        plt.imshow(np.reshape(x_test[img_index],(28,28)),cmap='gray')\n",
    "        plt.xticks([],[])\n",
    "        plt.yticks([],[])\n",
    "        plt.title(str(np.argmax(pred)))\n",
    "plt.tight_layout()\n",
    "file_helper.save_figure('mnist-convnet-predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
